# -*- coding: utf-8 -*-
"""Kopie von noise2noise_pytorch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1y3KIr4s5bjkBOWTheiOXt14zfcnCtD-a

<a href="https://colab.research.google.com/github/constantinpape/training-deep-learning-models-for-vison/blob/master/day3/noise2noise_pytorch.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

## Noise2Noise U-Net

In this notebook, we will implement "Noise2Noise: Learning Image Restoration without Clean Data". See the [original paper](https://arxiv.org/abs/1803.04189) for more details.

## Required dependencies
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
# %load_ext tensorboard
import os
import sys
sys.path.append(os.path.abspath('utils'))
import imageio
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image
import torch
from torch.utils.data import Dataset, DataLoader
from torch.utils.tensorboard import SummaryWriter
import torch.nn as nn
import torch.optim as optim
from torch.nn import functional as F
from torchvision import transforms
from vdsr_dataset import VdsrDataset
from augment_gaussian import AugmentGaussian
from augment_poisson import AugmentPoisson
from training_utils import train, validate
import tqdm
from psnr import PSNR
from unet import UNet

import utils
from skimage.metrics import peak_signal_noise_ratio

from pathlib import Path

"""## Data loading and preprocessing
For this excercise will use the [VDSR dataset](https://cv.snu.ac.kr/research/VDSR) containing 'clean' (no noise added) natural images.

Let's start with downloading and unzipping the data.
"""

"""Same as in previous excerices we're going to create our custom `Dataset` class for loading all the images from disk."""

# in the below implementation the 'noise_transform' should be a Callable which takes an image and returns
# a tuple of two images
"""Let's create the training dataset and show some of the images"""

TRAIN_DATA_PATH = 'vdsr_train'
# dummy transform, which just returns the input image twice
t = lambda x: (x, x)
train_data = VdsrDataset(TRAIN_DATA_PATH, noise_transform=t)


def show_random_dataset_image(dataset):
    idx = np.random.randint(0, len(dataset))    # take a random sample
    source, target = dataset[idx]                    # get the source and target image
    # convert (C,H,W) to (H,W,C)
    source = np.transpose(source, (1, 2, 0)) 
    target = np.transpose(target, (1, 2, 0))
    # covert to uint8
    source = utils.clip_to_uint8(source)
    target = utils.clip_to_uint8(target)
    
    f, axarr = plt.subplots(1, 2)               # make two plots on one figure
    axarr[0].imshow(source)                     # show the image
    axarr[1].imshow(target)                    # show the masks
    _ = [ax.axis('off') for ax in axarr]        # remove the axes
    print(f'Image size is {source.shape}')
    plt.show()

show_random_dataset_image(train_data)

"""Finally let's create our noise model. We will study the effect of corrupted targets using
synthetic additive Gaussian noise.

We randomize the noise standard deviation σ ∈ [0, 50] separately for
each training example to make it more difficult for the network, i.e., the network has to estimate the
magnitude of noise while removing it
"""

"""Let's create our noise augmentor, which randomize the noise standard deviation for source and target image separately."""

additive_gaussian_noise_train = AugmentGaussian((0, 50))
additive_poisson_noise_train = AugmentPoisson((0, 50))


# this time our 'noise_transform' Callable returns two images agumented with Gaussian noise with different standard deviation.
TRAIN_NOISE_TRANSFORM = lambda x: (additive_gaussian_noise_train(x), additive_gaussian_noise_train(x))
POISSON_NOISE_TRANSFORM = lambda x: (additive_poisson_noise_train(x), additive_poisson_noise_train(x))

# create the training Dataset with our noise transformer
TRAIN_DATA_PATH = 'vdsr_train'
train_data = VdsrDataset(TRAIN_DATA_PATH, noise_transform=TRAIN_NOISE_TRANSFORM)
train_data_clean = VdsrDataset(TRAIN_DATA_PATH, noise_transform=lambda x: (x, x))
train_data_poisson = VdsrDataset(TRAIN_DATA_PATH, noise_transform=POISSON_NOISE_TRANSFORM)
# create the DataLoader with batch size of 4
train_loader_noise = DataLoader(train_data, batch_size=4, shuffle=True)
train_loader_clean = DataLoader(train_data_clean, batch_size=4, shuffle=True)
train_loader_poisson = DataLoader(train_data_poisson, batch_size=4, shuffle=True)

show_random_dataset_image(train_data)

"""Create validation loader. This time we use a fixed standard deviation of 25 for the additive Gaussian noise. Notice that now the 2nd (i.e. target) image returned from the loader is not augmented with noise. Why?""" # Because the image on the right then becomes the validation image

additive_gaussian_noise_val = AugmentGaussian((25, 25))
# apply noise augmentation only to the input, leaving the target clean
VAL_NOISE_TRANSFORM = lambda x: (additive_gaussian_noise_val(x), x)

# create validation Dataset
VAL_DATA_PATH = 'vdsr_test'
val_data = VdsrDataset(VAL_DATA_PATH, noise_transform=VAL_NOISE_TRANSFORM)
# create DataLoader with a batch size of 4
val_loader = DataLoader(val_data, batch_size=4, shuffle=True)

show_random_dataset_image(val_data)

"""## U-net architecure 

We're going to use the same architectue as described in Appendix 1 of  J. Lehtinen, J. Munkberg, J. Hasselgren, S. Laine, T. Karras, M. Aittala, T. Aila, "Noise2Noise: Learning Image Restoration without Clean Data". Can you spot the main differences? What activation function has been used this time?

Notice that denoising is a regression problem, so this time we're not normalizing the output of the last convolution with a Sigmoid function and take the linear activation directly instead.
"""

"""Having the network architecture implemented, let's make a single forward pass with a random image in order to see that it's working"""

m = UNet(in_channels=3, out_channels=3)

idx = np.random.randint(0, len(train_data))
img = train_data[idx][0]
img = img.unsqueeze(0)

output = m(img)

"""## Loss and evaluation metrics

Since we're using the additive Gaussian noise, which has a zero mean, we will use an `L_2` (`MSE`) loss.

[Peak signal-to-noise ratio](https://en.wikipedia.org/wiki/Peak_signal-to-noi) will be used as our evaluation metric.
"""

LOSS_CRITERION = nn.MSELoss()

EVAL_METRIC = PSNR()

# check if we have  a gpu
if torch.cuda.is_available():
    print("GPU is available")
    device = torch.device("cuda:0")
else:
    print("GPU is not available")
    device = torch.device("cpu")

# Commented out IPython magic to ensure Python compatibility.
# start a tensorboard writer
# %tensorboard --logdir runs

# helper function to create the optimizer
def create_optimizer(learning_rate, model):
    optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=(0.9, 0.99))
    return optimizer

net = UNet(in_channels=3, out_channels=3)

# move the model to GPU
net = net.to(device)

# use adam optimizer
optimizer = create_optimizer(learning_rate=0.01, model=net)

def namestr(obj, namespace):
    return [name for name in namespace if namespace[name] is obj]

loaders = [(train_loader_poisson, 'train_loader_poisson'),(train_loader_noise, 'train_loader_noise'), (train_loader_clean, 'train_loader_clean')]

n_epochs = 40
for train_loader, loader_name in loaders:
    logger = SummaryWriter(f'runs/noise2noise_{loader_name}')
    print(f"\n\nTraining noise2noise for {n_epochs} epochs with loader {loader_name}")
    for epoch in tqdm.tqdm(range(n_epochs), total=n_epochs):
        # train
        train(net, train_loader, optimizer, LOSS_CRITERION, epoch, log_interval=25, tb_logger=logger, device=device)
        step = epoch * len(train_loader.dataset)
        # validate
        validate(net, val_loader, LOSS_CRITERION, EVAL_METRIC, step=step, tb_logger=logger, device = device)

"""## Exercises

1. Train a separete denoising model using clean target and compare the PSNR scores with those obtained with noise2noise model. Compare results of the two models visually in tensorboard.
**Hint** the only change that needs to be done in the loader is changing the noise transformer to return a clean image during training
```
TRAIN_NOISE_TRANSFORM = lambda x: (additive_gaussian_noise_train(x), x)
```
2. Train noise2noise with different noise model, e.g. Poisson noise with varying lambda.
"""



